{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Nikhil-Kadapala/NeuralNets/blob/main/standardNeuralNets/stdCNN_LIME.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6L2Do3b_ytm6"
   },
   "source": [
    "# Final Project CS852 - Foundations of Neural Networks (FALL 2024)\n",
    "\n",
    "Devin Borchard and Nikhil Kadapala\n",
    "\n",
    "Department of Computer Science, University of New Hampshire\n",
    "\n",
    "Nikhil.Kadapala@unh.edu     Devin.Borchard@unh.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICkcYT3Iytm9"
   },
   "source": [
    "This project explores the application of Convolutional Neural Networks (CNNs) for sentiment analysis and Interpretability using the LIME (Local Interpretable Model-agnostic Explanations) Evaluation. \n",
    "\n",
    "The project uses the Movie Reviews dataset from the Eraser Benchmark.\n",
    "\n",
    "The goal of this project is to evaluate the performance of CNNs for sentiment analysis and explain their predictions using LIME. \n",
    "\n",
    "We will explore the integration of LIME Explanations as a feedback to measure the alignment of the model's reasoning with human rationales extracted from the annotations in the Dataset.\n",
    "\n",
    "Based on the alignment scores, we will retrain the model by adjusting the weights of the features to teach the model to rationalize as closely possible to a human.\n",
    "\n",
    "ERASER: [Datasets](https://www.eraserbenchmark.com) and [Paper](https://arxiv.org/pdf/1911.03429)\n",
    "\n",
    "LIME: [Paper](https://arxiv.org/pdf/1602.04938) and  [Library/Package GitHub](https://github.com/marcotcr/lime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sr8uEiG3ytm9"
   },
   "source": [
    "# Notebook setup and PyTorch Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "LJ5b9esmytm-"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# uncomment one of these versions (depending on whether you are on a computer with a CPU or not)\n",
    "\n",
    "# GPU version\n",
    "# !conda install --yes --prefix {sys.prefix} pytorch torchvision cudatoolkit=10.2 -c pytorch\n",
    "\n",
    "# Just CPU\n",
    "# !conda install --yes --prefix {sys.prefix} pytorch torchvision cpuonly -c pytorch\n",
    "\n",
    "# install `Einops` for einstein-style tensor manipulation in pytorch\n",
    "# Also see https://github.com/arogozhnikov/einops\n",
    "# !conda install --yes --prefix {sys.prefix} einops  -c conda-forge\n",
    "\n",
    "# install lime \n",
    "# pip install lime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XSKM3pNDytnA",
    "outputId": "e038a50b-7458-438f-c2e6-b83d4e373c61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9774, 0.1293, 0.6123],\n",
      "        [0.6809, 0.6776, 0.6281],\n",
      "        [0.3946, 0.8147, 0.1052],\n",
      "        [0.9683, 0.1854, 0.4380],\n",
      "        [0.5929, 0.9348, 0.8326]])\n",
      "GPU/CUDA available?  False\n",
      "Torch version 2.5.1\n"
     ]
    }
   ],
   "source": [
    "# torch test\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "\n",
    "print(\"GPU/CUDA available? \", torch.cuda.is_available())\n",
    "\n",
    "print(\"Torch version\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIw0tI1IytnB"
   },
   "source": [
    "# **Extracting Traning, Validation, and Test Data**\n",
    "# Parse the data files to extract the reviews, classifications and annotations for each split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIrDTApeytnC"
   },
   "source": [
    "There are three files:\n",
    "- train.jsonl: containts 1600 training examples\n",
    "- val.jsonl: contains 200 validation examples\n",
    "- test.json: contains 199 test examples\n",
    "\n",
    "Each example includes:\n",
    "- annotation_id: a unique id for an example of the form negR_000 for negative examples and posR_000 for positive examples.\n",
    "- evidences: a list of rationales(specific parts of the review) given by humans that most influenced their classification decision.\n",
    "- classification: the class of the example\n",
    "\n",
    "The annotation_id of each example is the name of the file for the input text data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "pVM3qH6FytnD"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_data(file_path):\n",
    "    data = []                                               # Initialize an empty list to store the dictionaries\n",
    "\n",
    "    with open(file_path, 'r') as file:                      # Open the .jsonl file and read it line by line\n",
    "        for line in file:\n",
    "            annotation = json.loads(line)                   # Parse each line as JSON and append it to the list\n",
    "            id = annotation[\"annotation_id\"]\n",
    "            annotation[\"classification\"] = 1 if annotation['classification'] == \"POS\" else 0\n",
    "\n",
    "            with open(f\"./movies/docs/{id}\", 'r') as file:  # open the file named by annotation_id to extract the review text\n",
    "                content = file.read()\n",
    "                annotation['content'] = content.replace('\\n', ' ')\n",
    "                data.append(annotation)\n",
    "    return data\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "train_file_path = './movies/train.jsonl'\n",
    "val_file_path = './movies/val.jsonl'\n",
    "test_file_path = './movies/test.jsonl'\n",
    "\n",
    "train_data = parse_data(train_file_path)\n",
    "validation_data = parse_data(val_file_path)\n",
    "test_data = parse_data(test_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bijy4N-HytnD"
   },
   "source": [
    "# Functions to extract reviews, classifications, and annotations\n",
    "  Define a function\n",
    "\n",
    "  i) to retrieve an example and print the relevant information.\n",
    "\n",
    "  ii) to retrieve the content of the example review text\n",
    "\n",
    "  iii) to retrieve the classifications of the examples\n",
    "  \n",
    "  iv) to retrieve the annotations provided to support the classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hKGZxYzTytnE",
    "outputId": "1457c1f0-67f2-4c8a-ebb7-f4c5444ce2be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split: 1600 training examples\n",
      "               200 validation examples\n",
      "               199 test examples\n",
      "\n",
      "Retrieving Training Example [506].................\n",
      "\n",
      "Review content:\n",
      "this film is extraordinarily horrendous and i 'm not going to waste any more words on it .\n",
      "\n",
      "---------------------------- \n",
      "| Sentiment class: 0 - NEG | \n",
      "----------------------------\n",
      "\n",
      "Human rationales / Supporting Evidence:\n",
      "     -  extraordinarily horrendous\n"
     ]
    }
   ],
   "source": [
    "def print_example(data, index, print_content=True, print_classification=True, print_rationales=True ):\n",
    "    print(f'Retrieving Training Example [{index}].................\\n')\n",
    "    item = data[index]\n",
    "    classification = item['classification']\n",
    "    evidences = item['evidences']\n",
    "    content = item['content']\n",
    "    if print_content: print(f'Review content:\\n{content}\\n')\n",
    "    if print_classification: print('----------------------------',\n",
    "                                   '\\n| Sentiment class:',\n",
    "                                   classification,\n",
    "                                   (\"- NEG\" if not classification else \"- POS\"),\n",
    "                                   '|', '\\n----------------------------')\n",
    "    if print_rationales:\n",
    "        print('\\nHuman rationales / Supporting Evidence:')\n",
    "        for evidence in evidences:\n",
    "            print('     - ', evidence[0]['text'])\n",
    "\n",
    "def get_content(data, index):\n",
    "    item = data[index]\n",
    "    content = item['content']\n",
    "    return content\n",
    "\n",
    "def get_classes(data, index):\n",
    "    item = data[index]\n",
    "    classification = item['classification']\n",
    "    return classification\n",
    "\n",
    "def get_annotations(data, index):\n",
    "    item = data[index]\n",
    "    content = item['evidences']\n",
    "    annotations = [evidence[0]['text'] for evidence in content]\n",
    "    return annotations\n",
    "\n",
    "train_size = len(train_data)\n",
    "val_size = len(validation_data)\n",
    "test_size = len(test_data)\n",
    "\n",
    "print(f'Dataset split: {train_size} training examples')\n",
    "print(f'               {val_size} validation examples')\n",
    "print(f'               {test_size} test examples\\n')\n",
    "\n",
    "print_example(train_data, 506)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLQCckZ-wz1C"
   },
   "source": [
    "# Extraction of the rationales from the evidences metadata of each human annotation of reviews.\n",
    "\n",
    "Each annotation of the review is not the highlighted text/rationale itself but also contains metadata of the text. Use the function defined in the above cell to extract just the text and replace the evidences dictionary of the training, validation, and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-5ulEzugwz1C",
    "outputId": "48a33212-48f2-4cbd-d653-1f58a4c78a5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['extraordinarily horrendous']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_data)):\n",
    "    train_data[i]['evidences'] = get_annotations(train_data, i)\n",
    "\n",
    "for i in range(len(validation_data)):\n",
    "    validation_data[i]['evidences'] = get_annotations(validation_data, i)\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    test_data[i]['evidences'] = get_annotations(test_data, i)\n",
    "\n",
    "print(train_data[506]['evidences'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vc2rC9QTytnK"
   },
   "source": [
    "# Pre-trianed GloVe Embeddings of Training Examples\n",
    "Download the pretrained GloVe Embeddings of desired dimensions using gensim downlader.\n",
    "\n",
    "Save downloaded embeddings to a local file to avoid re-downloading when the kernel or notebook is restarted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "KWyAJ5D_ytnL",
    "outputId": "879d19b4-5054-4217-dfb6-37d862735b1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    ONLY if you get an error after `import gensim`: update your smart_open liberary\\n    #!conda install --yes --prefix {sys.prefix} smart_open\\n    restart your notebook\\n    see if `import gensim` works now\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Install gensim, to use word2vec word embeddings\n",
    "    Install gensim (for pre-trained word embeddings)\n",
    "    #!conda install --yes --prefix {sys.prefix} gensim\n",
    "\"\"\"\n",
    "#import gensim\n",
    "#import gensim.downloader\n",
    "\n",
    "\"\"\"\n",
    "    ONLY if you get an error after `import gensim`: update your smart_open liberary\n",
    "    #!conda install --yes --prefix {sys.prefix} smart_open\n",
    "    restart your notebook\n",
    "    see if `import gensim` works now\n",
    "\"\"\"\n",
    "#wv = gensim.downloader.load(\"glove-wiki-gigaword-50\")\n",
    "\n",
    "#import pickle\n",
    "\n",
    "#with open(\"glove_embeddings.pkl\", \"wb\") as f:\n",
    "    #pickle.dump(wv, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QqA5DXEEwz1D",
    "outputId": "0a3ed4d3-4c2d-4b05-bf8e-694e9f14ab51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.20356 , -0.8707  , -0.19172 ,  0.73862 ,  0.18494 ,  0.14926 ,\n",
       "        0.48079 , -0.21633 ,  0.72753 , -0.36912 ,  0.13397 , -0.1143  ,\n",
       "       -0.18075 , -0.64683 , -0.18484 ,  0.83575 ,  0.48179 ,  0.76026 ,\n",
       "       -0.50381 ,  0.80743 ,  1.2195  ,  0.3459  ,  0.22185 ,  0.31335 ,\n",
       "        1.2066  , -1.8441  ,  0.14064 , -0.99715 , -1.1402  ,  0.32342 ,\n",
       "        3.2128  ,  0.42708 ,  0.19504 ,  0.80113 ,  0.38555 , -0.12568 ,\n",
       "       -0.26533 ,  0.055264, -1.1557  ,  0.16836 , -0.82228 ,  0.20394 ,\n",
       "        0.089235, -0.60125 , -0.032878,  1.3735  , -0.51661 ,  0.29611 ,\n",
       "        0.23951 , -1.3801  ], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"glove_embeddings.pkl\", \"rb\") as f:\n",
    "    wv = pickle.load(f)\n",
    "\n",
    "# lookup the word vector for a word \"india\"\n",
    "wv['india']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "IFRN-vp2ytnM"
   },
   "outputs": [],
   "source": [
    "# downsampled embedding and zero vector for unknown words\n",
    "# note the following code assums the the word embedding dimensions are dividible by 5\n",
    "\n",
    "import einops # type: ignore\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import types\n",
    "\n",
    "def glove_embed(word:str, target_dim)->np.array:\n",
    "    '''Looks up word in embedding (downsampled to five dimensions), pads with beginning of embedding.\n",
    "       Returns zero vector for unknown words.\n",
    "    '''\n",
    "    # these parameters work for 50-dim glove embeddings (adjust for other embeddings)\n",
    "    sampled_dim = 5\n",
    "    sample_batches = 10\n",
    "\n",
    "    empty_vec=np.zeros(target_dim)\n",
    "    if word in wv:\n",
    "        w2v = wv[word] # lookup 50 dim vector\n",
    "        a=einops.reduce(w2v,'(d seg)-> d', \"sum\", seg=sample_batches)  # downsample\n",
    "        b=w2v[0:target_dim-sampled_dim]\n",
    "        return np.hstack([a,b])\n",
    "    else:\n",
    "        return empty_vec\n",
    "\n",
    "def glove_embed_sequences(sequence, target_dim):\n",
    "\n",
    "    if isinstance(sequence, list):\n",
    "        if len(sequence) == 0:\n",
    "            empty_seq = np.zeros(target_dim)\n",
    "            gloveTensor =  torch.tensor(empty_seq, dtype=torch.float)\n",
    "        else:\n",
    "            tokens = \",\".join(sequence)\n",
    "            words = tokens.split()\n",
    "            gloveTensor = torch.stack([torch.tensor(glove_embed(word, target_dim), dtype=torch.float) for word in words])\n",
    "    else:\n",
    "        tokens = sequence.split()\n",
    "        gloveTensor = torch.stack([torch.tensor(glove_embed(token, target_dim), dtype=torch.float) for token in tokens])\n",
    "\n",
    "    return gloveTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YFDJY6pMdHx"
   },
   "source": [
    "# Extract reviews, classifications, and rationales from the train, validation, and test datasets to convert them to Glove embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "XoZiHbVxytnN",
    "outputId": "48b33143-dded-4b2d-90b9-81531ded5c86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews in training data: 1600\n",
      "Max seq length of reviews: 2809\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>classification</th>\n",
       "      <th>evidences</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negR_000.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>['mind - fuck movie', 'the sad part is', 'down...</td>\n",
       "      <td>plot : two teen couples go to a church party ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negR_001.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"it 's pretty much a sunken ship\", 'sutherlan...</td>\n",
       "      <td>the happy bastard 's quick movie review damn t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negR_002.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>['the characters and acting is nothing spectac...</td>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negR_003.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>['dead on arrival', 'the characters stink', 's...</td>\n",
       "      <td>\" quest for camelot \" is warner bros . ' first...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negR_004.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>['it is highly derivative and somewhat boring'...</td>\n",
       "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  annotation_id  classification  \\\n",
       "0  negR_000.txt               0   \n",
       "1  negR_001.txt               0   \n",
       "2  negR_002.txt               0   \n",
       "3  negR_003.txt               0   \n",
       "4  negR_004.txt               0   \n",
       "\n",
       "                                           evidences  \\\n",
       "0  ['mind - fuck movie', 'the sad part is', 'down...   \n",
       "1  [\"it 's pretty much a sunken ship\", 'sutherlan...   \n",
       "2  ['the characters and acting is nothing spectac...   \n",
       "3  ['dead on arrival', 'the characters stink', 's...   \n",
       "4  ['it is highly derivative and somewhat boring'...   \n",
       "\n",
       "                                             content  \n",
       "0  plot : two teen couples go to a church party ,...  \n",
       "1  the happy bastard 's quick movie review damn t...  \n",
       "2  it is movies like these that make a jaded movi...  \n",
       "3  \" quest for camelot \" is warner bros . ' first...  \n",
       "4  synopsis : a mentally unstable man undergoing ...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the training dataset to a pandas dataframe\n",
    "train_df = pd.DataFrame(train_data)\n",
    "train_df.drop(columns=['query', 'query_type'], inplace=True)\n",
    "train_df['evidences'] = train_df['evidences'].astype(str)\n",
    "\n",
    "train_rationales = train_df['evidences']\n",
    "train_reviews = [get_content(train_data, i) for i in range(train_size)]\n",
    "train_classes = torch.tensor([get_classes(train_data, i) for i in range(train_size)], dtype=torch.float)\n",
    "\n",
    "print(\"Number of reviews in training data:\",len(train_reviews))\n",
    "print(\"Max seq length of reviews:\", np.max([len(review.split()) for review in train_reviews]))\n",
    "train_df.to_csv('train_data.csv', index=False)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "YUXL-ZR0Pujb",
    "outputId": "2216077b-8b4a-4677-97a9-7b9a0f5af397"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews in validation data: 200\n",
      "Max seq length of reviews: 1880\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>classification</th>\n",
       "      <th>evidences</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negR_800.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>['definitely the cinematic equivalent of a sle...</td>\n",
       "      <td>there were four movies that earned jamie lee c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negR_801.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>['overacts his psycho routine', 'deteriorates ...</td>\n",
       "      <td>according to hitchcock and various other filmm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negR_802.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>['so dull and pedestrian and nonsensical', 'bo...</td>\n",
       "      <td>if you 've been following william fichtner 's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negR_803.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>['takes the easy route out', 'most hampered no...</td>\n",
       "      <td>note : some may consider portions of the follo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negR_804.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>['poor choices', \"it 's downright depressing\",...</td>\n",
       "      <td>for his directoral debut , gary oldman chose a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  annotation_id  classification  \\\n",
       "0  negR_800.txt               0   \n",
       "1  negR_801.txt               0   \n",
       "2  negR_802.txt               0   \n",
       "3  negR_803.txt               0   \n",
       "4  negR_804.txt               0   \n",
       "\n",
       "                                           evidences  \\\n",
       "0  ['definitely the cinematic equivalent of a sle...   \n",
       "1  ['overacts his psycho routine', 'deteriorates ...   \n",
       "2  ['so dull and pedestrian and nonsensical', 'bo...   \n",
       "3  ['takes the easy route out', 'most hampered no...   \n",
       "4  ['poor choices', \"it 's downright depressing\",...   \n",
       "\n",
       "                                             content  \n",
       "0  there were four movies that earned jamie lee c...  \n",
       "1  according to hitchcock and various other filmm...  \n",
       "2  if you 've been following william fichtner 's ...  \n",
       "3  note : some may consider portions of the follo...  \n",
       "4  for his directoral debut , gary oldman chose a...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the validation dataset to a pandas dataframe\n",
    "val_df = pd.DataFrame(validation_data)\n",
    "val_df.drop(columns=['query', 'query_type'], inplace=True)\n",
    "val_df['evidences'] = val_df['evidences'].astype(str)\n",
    "\n",
    "val_rationales = val_df['evidences']\n",
    "val_reviews = [get_content(validation_data, i) for i in range(val_size)]\n",
    "val_classes = torch.tensor([get_classes(validation_data, i) for i in range(val_size)], dtype=torch.float)\n",
    "\n",
    "print(\"Number of reviews in validation data:\",len(val_reviews))\n",
    "print(\"Max seq length of reviews:\", np.max([len(review.split()) for review in val_reviews]))\n",
    "val_df.to_csv('val_data.csv', index=False)\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "Q4vG15P9OvtM",
    "outputId": "3df04dc4-79a8-47fa-fb9e-4c313ca7dc90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews in test data: 199\n",
      "Max seq length of reviews: 2122\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>classification</th>\n",
       "      <th>evidences</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negR_900.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>['i even giggled']</td>\n",
       "      <td>there may not be a critic alive who harbors as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negR_901.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>['rings']</td>\n",
       "      <td>renee zellweger stars as sonia , a young jewis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negR_902.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"there 're so many things to criticize about ...</td>\n",
       "      <td>there 're so many things to criticize about i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negR_903.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"do n't let this movie fool you into believin...</td>\n",
       "      <td>do n't let this movie fool you into believing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negR_904.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"is proof that hollywood does n't have a clue...</td>\n",
       "      <td>it 's a good thing most animated sci - fi movi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  annotation_id  classification  \\\n",
       "0  negR_900.txt               0   \n",
       "1  negR_901.txt               0   \n",
       "2  negR_902.txt               0   \n",
       "3  negR_903.txt               0   \n",
       "4  negR_904.txt               0   \n",
       "\n",
       "                                           evidences  \\\n",
       "0                                 ['i even giggled']   \n",
       "1                                          ['rings']   \n",
       "2  [\"there 're so many things to criticize about ...   \n",
       "3  [\"do n't let this movie fool you into believin...   \n",
       "4  [\"is proof that hollywood does n't have a clue...   \n",
       "\n",
       "                                             content  \n",
       "0  there may not be a critic alive who harbors as...  \n",
       "1  renee zellweger stars as sonia , a young jewis...  \n",
       "2  there 're so many things to criticize about i ...  \n",
       "3  do n't let this movie fool you into believing ...  \n",
       "4  it 's a good thing most animated sci - fi movi...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the test dataset to a pandas dataframe\n",
    "test_df = pd.DataFrame(test_data)\n",
    "test_df.drop(columns=['docids','query', 'query_type'], inplace=True)\n",
    "test_df['evidences'] = test_df['evidences'].astype(str)\n",
    "\n",
    "test_rationales = test_df['evidences']\n",
    "test_reviews = [get_content(test_data, i) for i in range(test_size)]\n",
    "test_classes = torch.tensor([get_classes(test_data, i) for i in range(test_size)], dtype=torch.float)\n",
    "\n",
    "print(\"Number of reviews in test data:\",len(test_reviews))\n",
    "print(\"Max seq length of reviews:\", np.max([len(review.split()) for review in test_reviews]))\n",
    "test_df.to_csv('test_data.csv', index=False)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_WbCl45wz1E"
   },
   "source": [
    "Extract validation set from the val.jsonl file and create a dataframe for it similar to the training set and save it to a csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbHzxzSlwz1E"
   },
   "source": [
    "# Convert the reviews & rationales to their corresponding Glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "VNDiwN3ecSIM"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_glove_dict(sequence, wv, set, embed_dim=50):\n",
    "    \"\"\"\n",
    "    Creates a dictionary mapping words in the vocabulary to their GloVe embeddings.\n",
    "    Words that don't exist are mapped to zero vectors.\n",
    "    \"\"\"\n",
    "    glove_dict = {}\n",
    "    empty_vec = np.zeros(embed_dim, dtype=np.float64)\n",
    "\n",
    "    for word in tqdm(sequence, desc=f\"Building {set} GloVe dictionary\"):\n",
    "        glove_dict[word] = wv[word] if word in wv else empty_vec\n",
    "\n",
    "    return glove_dict\n",
    "\n",
    "def get_w2GloVe(data, glove_dict, set, embed_dim=50, rationale=False):\n",
    "    \"\"\"\n",
    "    Retrieves the GloVe embeddings using the custom-built GloVe dictionary.\n",
    "    Args:\n",
    "        data: List of text reviews.\n",
    "        glove_dict (dict): custom-built GloVe dictionary.\n",
    "        embed_dim (int): Dimensions of GloVe embeddings.\n",
    "    Returns:\n",
    "        torch.Tensor: Padded tensor of GloVe embeddings to maintain uniform length.\n",
    "    \"\"\"\n",
    "    glove_reviews = []\n",
    "\n",
    "    if rationale:\n",
    "        for review in tqdm(data, desc=f\"Retrieving {set} GloVe Word Embeddings\"):\n",
    "            tokens = \",\".join(review)\n",
    "            words = tokens.split()\n",
    "            embeddings = [glove_dict.get(word, np.zeros(embed_dim)) for word in words]\n",
    "            glove_reviews.append(torch.tensor(embeddings, dtype=torch.float))\n",
    "    else:\n",
    "        for review in tqdm(data, desc=f\"Retrieving {set} GloVe Word Embeddings\"):\n",
    "            words = review.split()\n",
    "            embeddings = [glove_dict.get(word, np.zeros(embed_dim)) for word in words]\n",
    "            glove_reviews.append(torch.tensor(embeddings, dtype=torch.float))\n",
    "\n",
    "    return pad_sequence(glove_reviews, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nHdxXI-3cSIM",
    "outputId": "923db9f4-5510-463e-d244-a820d2fb606e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------\n",
      "Processing Reviews\n",
      "----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building training GloVe dictionary: 100%|██████████| 36659/36659 [00:00<00:00, 450900.84it/s]\n",
      "Building validation GloVe dictionary: 100%|██████████| 13896/13896 [00:00<00:00, 403970.45it/s]\n",
      "Building test GloVe dictionary: 100%|██████████| 13971/13971 [00:00<00:00, 317835.10it/s]\n",
      "Retrieving training GloVe Word Embeddings: 100%|██████████| 1600/1600 [00:08<00:00, 193.44it/s]\n",
      "Retrieving validation GloVe Word Embeddings: 100%|██████████| 200/200 [00:01<00:00, 179.82it/s]\n",
      "Retrieving test GloVe Word Embeddings: 100%|██████████| 199/199 [00:01<00:00, 181.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------\n",
      "Processing Rationales\n",
      "----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building training GloVe dictionary: 100%|██████████| 15318/15318 [00:00<00:00, 470790.79it/s]\n",
      "Building validation GloVe dictionary: 100%|██████████| 3335/3335 [00:00<00:00, 413785.06it/s]\n",
      "Building test GloVe dictionary: 100%|██████████| 1664/1664 [00:00<00:00, 998901.08it/s]\n",
      "Retrieving training GloVe Word Embeddings: 100%|██████████| 1600/1600 [00:00<00:00, 2132.11it/s]\n",
      "Retrieving validation GloVe Word Embeddings: 100%|██████████| 200/200 [00:00<00:00, 2792.56it/s]\n",
      "Retrieving test GloVe Word Embeddings: 100%|██████████| 199/199 [00:00<00:00, 6044.76it/s]\n"
     ]
    }
   ],
   "source": [
    "print(f\"----------------------------------------------------------------------------------------\\nProcessing Reviews\\n----------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "# Extract vocabulary(distinct words) from training, validation, and test data\n",
    "train_vocab = set(word for review in train_df['content'] for word in review.split())\n",
    "val_vocab = set(word for review in val_df['content'] for word in review.split())\n",
    "test_vocab = set(word for review in test_df['content'] for word in review.split())\n",
    "\n",
    "# Build the GloVe dictionary for the reviews\n",
    "glove_dict = create_glove_dict(train_vocab, wv, \"training\")\n",
    "glove_dict.update(create_glove_dict(val_vocab, wv, \"validation\"))\n",
    "glove_dict.update(create_glove_dict(test_vocab, wv, \"test\"))\n",
    "\n",
    "# Convert reviews to glove embeddings\n",
    "train_review_gloves = get_w2GloVe(train_df['content'], glove_dict, \"training\")\n",
    "val_review_gloves = get_w2GloVe(val_df['content'], glove_dict, \"validation\")\n",
    "test_review_gloves = get_w2GloVe(test_df['content'], glove_dict, \"test\")\n",
    "\n",
    "print(f\"\\n----------------------------------------------------------------------------------------\\nProcessing Rationales\\n----------------------------------------------------------------------------------------\\n\")\n",
    "\n",
    "#Extract vocabulary(distinct words) from training, validation, and test data for the rationales\n",
    "train_rationale_vocab = set(word for rationale in train_rationales for word in rationale.split())\n",
    "val_rationale_vocab = set(word for rationale in val_rationales for word in rationale.split())\n",
    "test_rationale_vocab = set(word for rationale in test_rationales for word in rationale.split())\n",
    "\n",
    "# Build the GloVe dictionary for the rationales\n",
    "dict_rat = create_glove_dict(train_rationale_vocab, wv, \"training\")\n",
    "dict_rat.update(create_glove_dict(val_rationale_vocab, wv, \"validation\"))\n",
    "dict_rat.update(create_glove_dict(test_rationale_vocab, wv, \"test\"))\n",
    "\n",
    "# Convert rationales to glove embeddings\n",
    "train_rationale_gloves = get_w2GloVe(train_rationales, glove_dict, \"training\", rationale=True)\n",
    "val_rationale_gloves = get_w2GloVe(val_rationales, glove_dict, \"validation\", rationale=True)\n",
    "test_rationale_gloves = get_w2GloVe(test_rationales, glove_dict, \"test\", rationale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsVWqfEmcSIM"
   },
   "source": [
    "Save the GloVe embeddings to local files for faster Access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "Pm21m4EZwz1F"
   },
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(\"train_reviews.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_review_gloves, f)\n",
    "\n",
    "with open(\"val_reviews.pkl\", \"wb\") as f:\n",
    "    pickle.dump(val_review_gloves, f)\n",
    "\n",
    "with open(\"test_reviews.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_review_gloves, f)\n",
    "\n",
    "with open(\"train_rationales.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_rationale_gloves, f)\n",
    "\n",
    "with open(\"val_rationales.pkl\", \"wb\") as f:\n",
    "    pickle.dump(val_rationale_gloves, f)\n",
    "\n",
    "with open(\"test_rationales.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_rationale_gloves, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TBPAqY3cSIN"
   },
   "source": [
    "# Extract the GloVe embeddings created above and a create a copy before batching them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "WgQLyJDGcSIN"
   },
   "outputs": [],
   "source": [
    "with open(\"train_reviews.pkl\", \"rb\") as f:\n",
    "    train_in = pickle.load(f)\n",
    "\n",
    "with open(\"train_rationales.pkl\", \"rb\") as f:\n",
    "    train_ev = pickle.load(f)\n",
    "\n",
    "with open(\"val_reviews.pkl\", \"rb\") as f:\n",
    "    val_in = pickle.load(f)\n",
    "\n",
    "with open(\"val_rationales.pkl\", \"rb\") as f:\n",
    "    val_ev = pickle.load(f)\n",
    "\n",
    "with open(\"test_reviews.pkl\", \"rb\") as f:\n",
    "    test_in = pickle.load(f)\n",
    "\n",
    "with open(\"test_rationales.pkl\", \"rb\") as f:\n",
    "    test_ev = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSzDGF43ytnN"
   },
   "source": [
    "Convert the training, validation, and test data(GloVe representations) including the rationales to batches using DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "wsgVwakDytnO"
   },
   "outputs": [],
   "source": [
    "train_inputs = TensorDataset(train_in, train_ev, train_classes)\n",
    "val_inputs = TensorDataset(val_in, val_ev, val_classes)\n",
    "test_inputs = TensorDataset(test_in, test_ev, test_classes)\n",
    "\n",
    "train_loader = DataLoader(train_inputs, batch_size=32, shuffle=False)\n",
    "val_loader = DataLoader(val_inputs, batch_size=25, shuffle=False)\n",
    "test_loader = DataLoader(test_inputs, batch_size=25, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2809, 50])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_in[0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPQy0BjBytnO"
   },
   "source": [
    "# Convolutional Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smXuMplUytnO"
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple, Union\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import lime # type: ignore\n",
    "from lime.lime_text import LimeTextExplainer # type: ignore\n",
    "\n",
    "class LIME_CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int,\n",
    "        cnn_config: List[Dict],\n",
    "    ) -> None:\n",
    "\n",
    "        super(LIME_CNN, self).__init__()\n",
    "\n",
    "        self.in_channels = embed_dim\n",
    "\n",
    "        self.config = cnn_config\n",
    "\n",
    "        self.cnn_layers = nn.ModuleList()\n",
    "\n",
    "        for index, config in enumerate(cnn_config):\n",
    "\n",
    "            if index == 0:\n",
    "                self.proj = nn.Linear(embed_dim, config['out_channels'])\n",
    "                self.in_channels = config['out_channels']\n",
    "\n",
    "            conv_layer = nn.Conv1d(\n",
    "                in_channels=self.in_channels,\n",
    "                out_channels=config['out_channels'],\n",
    "                kernel_size=config['kernel_size'],\n",
    "                stride=config['stride'],\n",
    "                padding=config['padding'],\n",
    "                bias=config['bias'],\n",
    "            )\n",
    "\n",
    "            self.cnn_layers.append(conv_layer)\n",
    "\n",
    "            if index == 0 or index == len(cnn_config) - 1:\n",
    "\n",
    "                maxPool_layer = nn.MaxPool1d(\n",
    "                    kernel_size=config['kernel_size'],\n",
    "                    stride=config['stride'],\n",
    "                    padding=config['padding'],\n",
    "                )\n",
    "                self.cnn_layers.append(maxPool_layer)\n",
    "\n",
    "            self.in_channels = config['out_channels']\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.class_names = ['Positive', 'Negative']\n",
    "\n",
    "        self.lime_explainer = LimeTextExplainer(class_names=self.class_names)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        X: Tensor,\n",
    "    ) -> Tensor:\n",
    "        X = self.proj(X)\n",
    "        X = X.permute(0, 2, 1)\n",
    "\n",
    "        #print(\"Input size in forward:\", X.size())\n",
    "        \n",
    "        for layer in self.cnn_layers:\n",
    "\n",
    "            X = self.relu(layer(X)) if isinstance(layer, nn.Conv1d) else layer(X)\n",
    "\n",
    "        X = X.mean(dim=-1)\n",
    "\n",
    "        self.fc_layer = nn.Linear(X.shape[1], 1)\n",
    "\n",
    "        y_hat = self.fc_layer(X)\n",
    "\n",
    "        y_hat = torch.sigmoid(y_hat).squeeze(-1)\n",
    "        print(y_hat.size())\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "    # define the classifier function that outputs the probabilities for both classes from the predicted probability of the examples\n",
    "    # Refer to the following link for more information: https://www.geeksforgeeks.org/understanding-the-predictproba-function-in-scikit-learns-svc/\n",
    "\n",
    "    def predict_proba(self, input_text):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = self.forward(train_in[0].unsqueeze(0))\n",
    "            probabs = preds.numpy()\n",
    "            probabs = np.hstack([1 - probabs, probabs])\n",
    "            return probabs\n",
    "        \n",
    "    def get_lime_explanation(self, example):\n",
    "        explanation = self.lime_explainer.explain_instance(example, self.predict_proba)\n",
    "        return explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOONmTg-ytnP"
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0IXthmm0ytnP",
    "outputId": "731a07f5-7e4b-4984-9836-faf4d551dde8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  64%|██████▍   | 32/50 [00:30<00:17,  1.04it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[153], line 66\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predictions, loss_list\n\u001b[0;32m     64\u001b[0m model \u001b[38;5;241m=\u001b[39m LIME_CNN(embed_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, cnn_config\u001b[38;5;241m=\u001b[39mloaded_config)\n\u001b[1;32m---> 66\u001b[0m preds, loss_list \u001b[38;5;241m=\u001b[39m train_model(\n\u001b[0;32m     67\u001b[0m                         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     68\u001b[0m                         train_set\u001b[38;5;241m=\u001b[39mtrain_loader,\n\u001b[0;32m     69\u001b[0m                         val_set\u001b[38;5;241m=\u001b[39mval_loader,\n\u001b[0;32m     70\u001b[0m                         n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     71\u001b[0m                         lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[0;32m     72\u001b[0m                     )\n",
      "Cell \u001b[1;32mIn[153], line 30\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_set, val_set, n_epochs, lr)\u001b[0m\n\u001b[0;32m     28\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     29\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 30\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     31\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     33\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "File \u001b[1;32mc:\\Users\\kadap\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    583\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\kadap\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[0;32m    348\u001b[0m     tensors,\n\u001b[0;32m    349\u001b[0m     grad_tensors_,\n\u001b[0;32m    350\u001b[0m     retain_graph,\n\u001b[0;32m    351\u001b[0m     create_graph,\n\u001b[0;32m    352\u001b[0m     inputs,\n\u001b[0;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    355\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\kadap\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Load the model configuration from a JSON file\n",
    "with open(\"model_config.json\", \"r\") as f:\n",
    "    loaded_config = json.load(f)\n",
    "\n",
    "def train_model(model, train_set, val_set, n_epochs, lr):\n",
    "\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_loss = float('inf') # initialize the best loss the model can achieve to infinity\n",
    "    patience = 0 # initialize the patience for early stopping if validation loss plateaus\n",
    "    loss_list = []\n",
    "    predictions = []\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        avg_loss = 0.0\n",
    "\n",
    "        for index, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs}\")):\n",
    "            #print(inputs.size())\n",
    "            inputs, rationales, labels = batch\n",
    "            #print(inputs.size())\n",
    "            pred = model(inputs)\n",
    "            predictions.append(pred)\n",
    "            loss = criterion(pred, labels)\n",
    "            train_loss += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        loss_list.append(train_loss)\n",
    "        print(f\"Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "        explanation = model.get_lime_explanation(train_reviews[0])\n",
    "        print(explanation.as_list())\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        tp = 0\n",
    "        num_labels = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs, rationales, labels = batch\n",
    "                pred = model(inputs)\n",
    "                loss = criterion(pred, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                y_hats = (pred > 0.5).float()\n",
    "                tp += torch.sum(y_hats == labels).item()\n",
    "                num_labels += labels.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = tp / num_labels\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\\n\")\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_model_state.pt\")\n",
    "\n",
    "    return predictions, loss_list\n",
    "\n",
    "model = LIME_CNN(embed_dim=50, cnn_config=loaded_config)\n",
    "\n",
    "preds, loss_list = train_model(\n",
    "                        model=model,\n",
    "                        train_set=train_loader,\n",
    "                        val_set=val_loader,\n",
    "                        n_epochs=1,\n",
    "                        lr=0.01,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "nL7dPN8rmMzL",
    "outputId": "ba6b2403-2868-405c-dec8-697d0a331e95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "index=%{x}<br>loss=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0
         ],
         "xaxis": "x",
         "y": [
          2.7767505489403264
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "index"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotly import express as px\n",
    "print(len(preds))\n",
    "loss_list = pd.DataFrame(loss_list)\n",
    "loss_list.columns = ['loss']\n",
    "loss_list.head()\n",
    "\n",
    "fig = px.scatter(loss_list, x=loss_list.index, y='loss')\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
