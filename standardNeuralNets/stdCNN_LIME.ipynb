{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhil-Kadapala/NeuralNets/blob/main/standardNeuralNets/stdCNN_LIME.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L2Do3b_ytm6"
      },
      "source": [
        "# Final Project CS852 - Foundations of Neural Networks (FALL 2024)\n",
        "\n",
        "Devin Borchard and Nikhil Kadapala\n",
        "\n",
        "Department of Computer Science, University of New Hampshire\n",
        "\n",
        "Nikhil.Kadapala@unh.edu     Devin.Borchard@unh.edu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICkcYT3Iytm9"
      },
      "source": [
        "This project explores the application of Convolutional Neural Networks (CNNs) for sentiment analysis and Interpretability using the LIME (Local Interpretable Model-agnostic Explanations) Evaluation.\n",
        "\n",
        "The project uses the Movie Reviews dataset from the Eraser Benchmark.\n",
        "\n",
        "The goal of this project is to evaluate the performance of CNNs for sentiment analysis and explain their predictions using LIME.\n",
        "\n",
        "We will explore the integration of LIME Explanations as a feedback to measure the alignment of the model's reasoning with human rationales extracted from the annotations in the Dataset.\n",
        "\n",
        "Based on the alignment scores, we will retrain the model by adjusting the weights of the features to teach the model to rationalize as closely possible to a human.\n",
        "\n",
        "ERASER: [Datasets](https://www.eraserbenchmark.com) and [Paper](https://arxiv.org/pdf/1911.03429)\n",
        "\n",
        "LIME: [Paper](https://arxiv.org/pdf/1602.04938) and  [Library/Package GitHub](https://github.com/marcotcr/lime)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sr8uEiG3ytm9"
      },
      "source": [
        "# Notebook setup and PyTorch Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LJ5b9esmytm-",
        "outputId": "9b1e1828-0d76-425b-dabe-8a7191237f62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lime in /usr/local/lib/python3.10/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.6)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.5.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.24.0)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.4.2)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (11.0.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# uncomment one of these versions (depending on whether you are on a computer with a CPU or not)\n",
        "\n",
        "# GPU version\n",
        "# !conda install --yes --prefix {sys.prefix} pytorch torchvision cudatoolkit=10.2 -c pytorch\n",
        "\n",
        "# Just CPU\n",
        "# !conda install --yes --prefix {sys.prefix} pytorch torchvision cpuonly -c pytorch\n",
        "\n",
        "# install `Einops` for einstein-style tensor manipulation in pytorch\n",
        "# Also see https://github.com/arogozhnikov/einops\n",
        "# !conda install --yes --prefix {sys.prefix} einops  -c conda-forge\n",
        "\n",
        "# install lime\n",
        "!pip install lime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSKM3pNDytnA",
        "outputId": "75f10441-ff30-4b8e-bae7-94a251e5bfe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8649, 0.6170, 0.4305],\n",
            "        [0.1642, 0.8773, 0.7422],\n",
            "        [0.8121, 0.6658, 0.3955],\n",
            "        [0.5433, 0.9812, 0.6379],\n",
            "        [0.0540, 0.5362, 0.9773]])\n",
            "GPU/CUDA available?  True\n",
            "Torch version 2.5.1+cu121\n"
          ]
        }
      ],
      "source": [
        "# torch test\n",
        "import torch\n",
        "x = torch.rand(5, 3)\n",
        "print(x)\n",
        "\n",
        "print(\"GPU/CUDA available? \", torch.cuda.is_available())\n",
        "\n",
        "print(\"Torch version\", torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/Nikhil-Kadapala/NeuralNets.git"
      ],
      "metadata": {
        "id": "9E4xzHkRB0sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QNeT-9eMWwR",
        "outputId": "0259bcf4-c3af-4c08-d148-8afa2bd36e2f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIw0tI1IytnB"
      },
      "source": [
        "# **Extracting Traning, Validation, and Test Data**\n",
        "# Parse the data files to extract the reviews, classifications and annotations for each split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIrDTApeytnC"
      },
      "source": [
        "There are three files:\n",
        "- train.jsonl: containts 1600 training examples\n",
        "- val.jsonl: contains 200 validation examples\n",
        "- test.json: contains 199 test examples\n",
        "\n",
        "Each example includes:\n",
        "- annotation_id: a unique id for an example of the form negR_000 for negative examples and posR_000 for positive examples.\n",
        "- evidences: a list of rationales(specific parts of the review) given by humans that most influenced their classification decision.\n",
        "- classification: the class of the example\n",
        "\n",
        "The annotation_id of each example is the name of the file for the input text data\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pVM3qH6FytnD"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def parse_data(file_path):\n",
        "    data = []                                               # Initialize an empty list to store the dictionaries\n",
        "\n",
        "    with open(file_path, 'r') as file:                      # Open the .jsonl file and read it line by line\n",
        "        for line in file:\n",
        "            annotation = json.loads(line)                   # Parse each line as JSON and append it to the list\n",
        "            id = annotation[\"annotation_id\"]\n",
        "            annotation[\"classification\"] = 1 if annotation['classification'] == \"POS\" else 0\n",
        "\n",
        "            with open(f\"./drive/MyDrive/NeuralNets/standardNeuralNets/movies/docs/{id}\", 'r') as file:  # open the file named by annotation_id to extract the review text\n",
        "                content = file.read()\n",
        "                annotation['content'] = content.replace('\\n', ' ')\n",
        "                data.append(annotation)\n",
        "    return data\n",
        "\n",
        "# Specify the path to your JSON file\n",
        "train_file_path = './drive/MyDrive/NeuralNets/standardNeuralNets/movies/train.jsonl'\n",
        "val_file_path = './drive/MyDrive/NeuralNets/standardNeuralNets/movies/val.jsonl'\n",
        "test_file_path = './drive/MyDrive/NeuralNets/standardNeuralNets/movies/test.jsonl'\n",
        "\n",
        "train_data = parse_data(train_file_path)\n",
        "validation_data = parse_data(val_file_path)\n",
        "test_data = parse_data(test_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bijy4N-HytnD"
      },
      "source": [
        "# Functions to extract reviews, classifications, and annotations\n",
        "  Define a function\n",
        "\n",
        "  i) to retrieve an example and print the relevant information.\n",
        "\n",
        "  ii) to retrieve the content of the example review text\n",
        "\n",
        "  iii) to retrieve the classifications of the examples\n",
        "  \n",
        "  iv) to retrieve the annotations provided to support the classifications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hKGZxYzTytnE",
        "outputId": "fb806bde-eae4-46d2-da6a-81412ccf4d90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split: 1600 training examples\n",
            "               200 validation examples\n",
            "               199 test examples\n",
            "\n",
            "Retrieving Training Example [506].................\n",
            "\n",
            "Review content:\n",
            "this film is extraordinarily horrendous and i 'm not going to waste any more words on it .\n",
            "\n",
            "---------------------------- \n",
            "| Sentiment class: 0 - NEG | \n",
            "----------------------------\n",
            "\n",
            "Human rationales / Supporting Evidence:\n",
            "     -  extraordinarily horrendous\n"
          ]
        }
      ],
      "source": [
        "def print_example(data, index, print_content=True, print_classification=True, print_rationales=True ):\n",
        "    print(f'Retrieving Training Example [{index}].................\\n')\n",
        "    item = data[index]\n",
        "    classification = item['classification']\n",
        "    evidences = item['evidences']\n",
        "    content = item['content']\n",
        "    if print_content: print(f'Review content:\\n{content}\\n')\n",
        "    if print_classification: print('----------------------------',\n",
        "                                   '\\n| Sentiment class:',\n",
        "                                   classification,\n",
        "                                   (\"- NEG\" if not classification else \"- POS\"),\n",
        "                                   '|', '\\n----------------------------')\n",
        "    if print_rationales:\n",
        "        print('\\nHuman rationales / Supporting Evidence:')\n",
        "        for evidence in evidences:\n",
        "            print('     - ', evidence[0]['text'])\n",
        "\n",
        "def get_content(data, index):\n",
        "    item = data[index]\n",
        "    content = item['content']\n",
        "    return content\n",
        "\n",
        "def get_classes(data, index):\n",
        "    item = data[index]\n",
        "    classification = item['classification']\n",
        "    return classification\n",
        "\n",
        "def get_annotations(data, index):\n",
        "    item = data[index]\n",
        "    content = item['evidences']\n",
        "    annotations = [evidence[0]['text'] for evidence in content]\n",
        "    return annotations\n",
        "\n",
        "train_size = len(train_data)\n",
        "val_size = len(validation_data)\n",
        "test_size = len(test_data)\n",
        "\n",
        "print(f'Dataset split: {train_size} training examples')\n",
        "print(f'               {val_size} validation examples')\n",
        "print(f'               {test_size} test examples\\n')\n",
        "\n",
        "print_example(train_data, 506)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLQCckZ-wz1C"
      },
      "source": [
        "# Extraction of the rationales from the evidences metadata of each human annotation of reviews.\n",
        "\n",
        "Each annotation of the review is not the highlighted text/rationale itself but also contains metadata of the text. Use the function defined in the above cell to extract just the text and replace the evidences dictionary of the training, validation, and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5ulEzugwz1C",
        "outputId": "8e0ee53c-aca4-4b17-be33-a4fe29e0f1a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['extraordinarily horrendous']\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(train_data)):\n",
        "    train_data[i]['evidences'] = get_annotations(train_data, i)\n",
        "\n",
        "for i in range(len(validation_data)):\n",
        "    validation_data[i]['evidences'] = get_annotations(validation_data, i)\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "    test_data[i]['evidences'] = get_annotations(test_data, i)\n",
        "\n",
        "print(train_data[506]['evidences'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc2rC9QTytnK"
      },
      "source": [
        "# Pre-trianed GloVe Embeddings of Training Examples\n",
        "Download the pretrained GloVe Embeddings of desired dimensions using gensim downlader.\n",
        "\n",
        "Save downloaded embeddings to a local file to avoid re-downloading when the kernel or notebook is restarted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWyAJ5D_ytnL",
        "outputId": "c9806410-8a80-460e-985f-c66ee0468192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    ONLY if you get an error after `import gensim`: update your smart_open liberary\\n    #!conda install --yes --prefix {sys.prefix} smart_open\\n    restart your notebook\\n    see if `import gensim` works now\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "\"\"\"\n",
        "    Install gensim, to use word2vec word embeddings\n",
        "    Install gensim (for pre-trained word embeddings)\n",
        "    #!conda install --yes --prefix {sys.prefix} gensim\n",
        "\"\"\"\n",
        "#import gensim\n",
        "#import gensim.downloader\n",
        "\n",
        "\"\"\"\n",
        "    ONLY if you get an error after `import gensim`: update your smart_open liberary\n",
        "    #!conda install --yes --prefix {sys.prefix} smart_open\n",
        "    restart your notebook\n",
        "    see if `import gensim` works now\n",
        "\"\"\"\n",
        "#wv = gensim.downloader.load(\"glove-wiki-gigaword-50\")\n",
        "\n",
        "#import pickle\n",
        "\n",
        "#with open(\"glove_embeddings.pkl\", \"wb\") as f:\n",
        "    #pickle.dump(wv, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqA5DXEEwz1D",
        "outputId": "f8d3053c-ccfe-4e19-ae47-06018d92a285"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.20356 , -0.8707  , -0.19172 ,  0.73862 ,  0.18494 ,  0.14926 ,\n",
              "        0.48079 , -0.21633 ,  0.72753 , -0.36912 ,  0.13397 , -0.1143  ,\n",
              "       -0.18075 , -0.64683 , -0.18484 ,  0.83575 ,  0.48179 ,  0.76026 ,\n",
              "       -0.50381 ,  0.80743 ,  1.2195  ,  0.3459  ,  0.22185 ,  0.31335 ,\n",
              "        1.2066  , -1.8441  ,  0.14064 , -0.99715 , -1.1402  ,  0.32342 ,\n",
              "        3.2128  ,  0.42708 ,  0.19504 ,  0.80113 ,  0.38555 , -0.12568 ,\n",
              "       -0.26533 ,  0.055264, -1.1557  ,  0.16836 , -0.82228 ,  0.20394 ,\n",
              "        0.089235, -0.60125 , -0.032878,  1.3735  , -0.51661 ,  0.29611 ,\n",
              "        0.23951 , -1.3801  ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"./drive/MyDrive/NeuralNets/standardNeuralNets/glove_embeddings.pkl\", \"rb\") as f:\n",
        "    wv = pickle.load(f)\n",
        "\n",
        "# lookup the word vector for a word \"india\"\n",
        "wv['india']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YFDJY6pMdHx"
      },
      "source": [
        "# Extract reviews, classifications, and rationales from the train, validation, and test datasets to convert them to Glove embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "XoZiHbVxytnN",
        "outputId": "3f4dd3f7-3684-41af-e27c-96c5c8bdace5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of reviews in training data: 1600\n",
            "Max seq length of reviews: 2809\n",
            "Size of training classes: torch.Size([1600])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  annotation_id  classification  \\\n",
              "0  negR_000.txt               0   \n",
              "1  negR_001.txt               0   \n",
              "2  negR_002.txt               0   \n",
              "3  negR_003.txt               0   \n",
              "4  negR_004.txt               0   \n",
              "\n",
              "                                           evidences  \\\n",
              "0  ['mind - fuck movie', 'the sad part is', 'down...   \n",
              "1  [\"it 's pretty much a sunken ship\", 'sutherlan...   \n",
              "2  ['the characters and acting is nothing spectac...   \n",
              "3  ['dead on arrival', 'the characters stink', 's...   \n",
              "4  ['it is highly derivative and somewhat boring'...   \n",
              "\n",
              "                                             content  \n",
              "0  plot : two teen couples go to a church party ,...  \n",
              "1  the happy bastard 's quick movie review damn t...  \n",
              "2  it is movies like these that make a jaded movi...  \n",
              "3  \" quest for camelot \" is warner bros . ' first...  \n",
              "4  synopsis : a mentally unstable man undergoing ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1287fe7-4186-4838-89c0-b51982f275f9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotation_id</th>\n",
              "      <th>classification</th>\n",
              "      <th>evidences</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negR_000.txt</td>\n",
              "      <td>0</td>\n",
              "      <td>['mind - fuck movie', 'the sad part is', 'down...</td>\n",
              "      <td>plot : two teen couples go to a church party ,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negR_001.txt</td>\n",
              "      <td>0</td>\n",
              "      <td>[\"it 's pretty much a sunken ship\", 'sutherlan...</td>\n",
              "      <td>the happy bastard 's quick movie review damn t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negR_002.txt</td>\n",
              "      <td>0</td>\n",
              "      <td>['the characters and acting is nothing spectac...</td>\n",
              "      <td>it is movies like these that make a jaded movi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negR_003.txt</td>\n",
              "      <td>0</td>\n",
              "      <td>['dead on arrival', 'the characters stink', 's...</td>\n",
              "      <td>\" quest for camelot \" is warner bros . ' first...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negR_004.txt</td>\n",
              "      <td>0</td>\n",
              "      <td>['it is highly derivative and somewhat boring'...</td>\n",
              "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1287fe7-4186-4838-89c0-b51982f275f9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e1287fe7-4186-4838-89c0-b51982f275f9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e1287fe7-4186-4838-89c0-b51982f275f9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-082feca2-776f-40e8-8e27-9d77627476f7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-082feca2-776f-40e8-8e27-9d77627476f7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-082feca2-776f-40e8-8e27-9d77627476f7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 1600,\n  \"fields\": [\n    {\n      \"column\": \"annotation_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1600,\n        \"samples\": [\n          \"negR_526.txt\",\n          \"negR_354.txt\",\n          \"negR_168.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"classification\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"evidences\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1600,\n        \"samples\": [\n          \"['so full of plot holes and non characters as to be sure to be the recipient of next years \\\" razzie \\\" award', 'there is so much wrong with this film', 'reeks almost as bad as the piles of rotting fish used to trap the beast', 'the movie has little or no depth', 'plot holes', 'should be ashamed of themselves', 'bleak and ugly looking', \\\"i sincerely hope that i 've completely spoiled any interest\\\", 'without a doubt the loudest , longest , and ultimately most amateurishly written film ever released', 'the performances in the film are singularly bland', 'without a doubt the most brain dead motion picture of the decade']\",\n          \"[\\\"wow , a film without any redeeming qualities whatsoever . i 'm amazed that someone thought this was a story that must be told on screen\\\", \\\"even i 'm offended by it\\\", \\\"there 's just an endless stream of profanity and naked breasts\\\", 'there was no comedy in the film']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1599,\n        \"samples\": [\n          \"moviemaking is a lot like being the general manager of an nfl team in the post - salary cap era -- you 've got to know how to allocate your resources . every dollar spent on a free - agent defensive tackle is one less dollar than you can spend on linebackers or safeties or centers . in the nfl , this leads to teams like the detroit lions , who boast a superstar running back with a huge contract , but can only field five guys named herb to block for him . in the movies , you end up with films like \\\" spawn \\\" , with a huge special - effects budget but not enough money to hire any recognizable actors . jackie chan is the barry sanders of moviemaking . he spins and darts across the screen like sanders cutting back through the defensive line . watching jackie in operation condor as he drives his motorcycle through the crowded streets of madrid , fleeing an armada of pursuers in identical black compact cars , is reminiscent of sanders running for daylight with the chicago bears in hot pursuit , except that sanders does n't have to worry about rescuing runaway baby carriages . but like the lions star , jackie does n't have anybody to block for him . almost every cent that 's invested in a jackie chan movie goes for stunts , and as chan does his own stunts , the rest of the money goes to pay his hospital bills . this leaves about 75 cents to pay for things like directors ( chan directs ) , scripts and dubbing and supporting characters , not to mention the hideous title sequence . this also explains why the movie was shot in odd places like morocco and spain . ( chan 's first release in this country , \\\" rumble in the bronx \\\" , was supposedly set in new york , but was filmed in vancouver , and in the chase scenes the canadian rockies are clearly visible . ) heck , jackie does n't even have enough money for a haircut , looks like , much less a personal hairstylist . in condor , chan plays the same character he 's always played , himself , a mixture of bruce lee and tim allen , a master of both kung - fu and slapstick - fu . jackie is sent by the un to retrieve a cache of lost nazi gold in the north african desert , and is chased by a horde of neo - nazi sympathizers and two stereotypical arabs ( one of the things i like about jackie chan movies : no political correctness ) . he is joined by three women , who have little to do except scream , \\\" jackie , save us ! \\\" , and misuse firearms . the villain is an old nazi whose legs were broken in the secret base so that he has to be carried everywhere , and he 's more pathetic than evil . en route , we have an extended motorcycle chase scene , a hilarious fight in the moroccan version of motel 6 with the neo - nazis , and two confrontations with savage natives . once at the secret desert base , there is a long chop - socky sequence , followed by the film 's centerpiece , a wind - tunnel fight that 's even better than the one in face / off . this is where the money was spent , on well - choreographed kung - fu sequences , on giant kevlar hamster balls , on smashed - up crates of bananas , and on scorpions . ignore the gaping holes in the plot ( how , exactly , if the villain 's legs were broken , did he escape from the secret nazi base , and why did n't he take the key with him ? ) . do n't worry about the production values , or what , exactly , the japanese girl was doing hitchhiking across the sahara . just go see the movie . operation condor has pretentions of being a \\\" raiders of the lost ark \\\" knockoff , but one wonders what jackie could do with the raiders franchise blocking for him -- with a lawrence kazdan screenplay , a john williams score , spielberg directing and george lucas producing , condor might be an a+ movie . however , you 've got to go with what you 've got , and what you 've got in jackie chan is something special -- a talent that mainstream hollywood should , could , and ought to utilize .\",\n          \"\\\" something is fishy in the state of universal . \\\" about ten years back , with the unexpected success of mad max and the road warrior , post - apocalypse nitty - gritty survival yarns became popular at the movies . we 've always had movies of this nature ; on the beach , the end of the world , damnation alley , the ultimate warrior , and so on . to date , the most smoothly done were straightforward \\\" haircuts \\\" of the classic western plot , like the lone gunman who comes to town and protects the widow and the son against an evil organization , usually one in possession of some critical resource , like water , feed range , or a mining claim . most of these grew out of venerable , but solid hero yarns like the virginian and shane . ( my personal favorite is a patrick swayze movie called steel dawn , which was fairly well made on a small budget . ) now we have waterworld , which again brings the traditional lone gunman to town to rescue the young widow and her daughter . ( well , she 's not a widow , and the kid is n't her daughter , but you get the idea . ) the lady is helen , played by the stunning jean tripplehorn , who is n't given a chance to be stunning , or even interesting , by the mediocre and unimaginative script . the child enola , played by tina majorino , is living proof that a child actor need not be a bad thing to have in a movie ; she outshines her material all the way through . in simple , the scene is earth , hundreds of years from now . the polar ice caps have melted , and somehow produced enough water to inundate the entire planet . the few remaining people live in boats and floating colonies , and survive by trade , theft , or piracy . somehow an oil tanker has survived the centuries , and its inhabitants , called \\\" smokers , \\\" are able to keep gasoline engines running despite the dearth of replacement parts and raw materials , so the bad guys have outboard engines , and fast - moving boats , airplanes , and jet skis . enola , found at sea as a young girl , has a mysterious map no one can read tattooed on her back . we suspect early on that it is the way to the mythical \\\" dryland , \\\" the place where trees , crops , and animals grow , and what plot there is hinges on who has enola . the psycho ruler of the smokers , the \\\" deacon , \\\" is trying to get her and find his way to dryland . played with typical self - lampooning , rug - chewing histrionics by dennis hopper , \\\" deacon \\\" is the only thing in the movie that 's close to amusing . his performance is * almost * laughable , but there just is n't enough there to be funny . the star ( and a co - producer ) is kevin costner . he 's playing an un - named lone denizen of the sea , a man called the \\\" mariner , \\\" who turns out to be a gilled , water - breathing mutant with webbed feet . very little is done with this . the script ignores the ineffectuality of gills in supplying enough oxygen to support a human metabolism ; it ignores the fact that even with both ice caps completely melted , much of the earth 's surface would still be above water ; and it ignores the blatant impossibility of the cultures and technology shown . ( canned meat does * not * last for centuries ; ammunition does * not * fire after it 's more than a few decades old ; and so on , and so on . . . ) i 'm quite fond of tina majorino 's previous work , very impressed by jean tripplehorn 's past accomplishments , and still speechless over costner 's dances with wolves . but this movie could destroy the careers of anyone associated with it ! this movie cost one hundred and eighty - two million dollars , and there 's * nothing * in it we have n't seen before , done better on only a few percent of the cost of this turkey . at 125 minutes of material , this movie cost over one point four million dollars per minute to make . the budget of this movie * could * have given us over thirty movies ; it could have paid for six years of a prime - time sf tv series with expensive fx work , or ten years of an sf tv series with good digital fx . in sum , this movie is beneath contempt . it has nothing new to offer , it has a script that could easily have been bettered by the people who write comic books for dc , and it spent more money than the national budget of a small nation . if you * have * to go see it , see it on a four - dollar matinee . otherwise you 'll find yourself sneering at you every time you pass a reflective surface , for weeks .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# convert the training dataset to a pandas dataframe\n",
        "train_df = pd.DataFrame(train_data)\n",
        "train_df.drop(columns=['query', 'query_type'], inplace=True)\n",
        "train_df['evidences'] = train_df['evidences'].astype(str)\n",
        "\n",
        "train_rationales = train_df['evidences']\n",
        "train_reviews = [get_content(train_data, i) for i in range(train_size)]\n",
        "train_classes = torch.tensor([get_classes(train_data, i) for i in range(train_size)], dtype=torch.float)\n",
        "train_classes = torch.stack([train_classes]).squeeze(0) # convert the classes to binary tensor for two classes (pos & neg)\n",
        "print(\"Number of reviews in training data:\",len(train_reviews))\n",
        "print(\"Max seq length of reviews:\", np.max([len(review.split()) for review in train_reviews]))\n",
        "print(\"Size of training classes:\", train_classes.size())\n",
        "train_df.to_csv('./drive/MyDrive/NeuralNets/standardNeuralNets/train_data.csv', index=False)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUXL-ZR0Pujb",
        "outputId": "3eed540a-ad89-4455-845c-a8d645e3b86d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of reviews in validation data: 200\n",
            "Max seq length of reviews: 1880\n",
            "Size of training classes: torch.Size([1600])\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n"
          ]
        }
      ],
      "source": [
        "# convert the validation dataset to a pandas dataframe\n",
        "val_df = pd.DataFrame(validation_data)\n",
        "val_df.drop(columns=['query', 'query_type'], inplace=True)\n",
        "val_df['evidences'] = val_df['evidences'].astype(str)\n",
        "\n",
        "val_rationales = val_df['evidences']\n",
        "val_reviews = [get_content(validation_data, i) for i in range(val_size)]\n",
        "val_classes = torch.tensor([get_classes(validation_data, i) for i in range(val_size)], dtype=torch.float)\n",
        "val_classes = torch.stack([val_classes]).squeeze(0) # convert the classes to binary tensor for two classes (pos & neg)\n",
        "\n",
        "print(\"Number of reviews in validation data:\",len(val_reviews))\n",
        "print(\"Max seq length of reviews:\", np.max([len(review.split()) for review in val_reviews]))\n",
        "print(\"Size of training classes:\", train_classes.size())\n",
        "val_df.to_csv('./drive/MyDrive/NeuralNets/standardNeuralNets/val_data.csv', index=False)\n",
        "val_df.head()\n",
        "print(val_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "Q4vG15P9OvtM",
        "outputId": "471008c4-da4a-4782-af11-30c2a4f1ce8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of reviews in test data: 199\n",
            "Max seq length of reviews: 2122\n",
            "Size of training classes: torch.Size([1600])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  annotation_id  classification  \\\n",
              "0  negR_900.txt               0   \n",
              "1  negR_901.txt               0   \n",
              "2  negR_902.txt               0   \n",
              "3  negR_903.txt               0   \n",
              "4  negR_904.txt               0   \n",
              "\n",
              "                                           evidences  \\\n",
              "0                                 ['i even giggled']   \n",
              "1                                          ['rings']   \n",
              "2  [\"there 're so many things to criticize about ...   \n",
              "3  [\"do n't let this movie fool you into believin...   \n",
              "4  [\"is proof that hollywood does n't have a clue...   \n",
              "\n",
              "                                             content  \n",
              "0  there may not be a critic alive who harbors as...  \n",
              "1  renee zellweger stars as sonia , a young jewis...  \n",
              "2  there 're so many things to criticize about i ...  \n",
              "3  do n't let this movie fool you into believing ...  \n",
              "4  it 's a good thing most animated sci - fi movi...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0292091c-68eb-4208-b3d1-c6dc6f3bc630\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotation_id</th>\n",
              "      <th>classification</th>\n",
              "      <th>evidences</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negR_900.txt</td>\n",
              "      <td>0</td>\n",
              "      <td>['i even giggled']</td>\n",
              "      <td>there may not be a critic alive who harbors as...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negR_901.txt</td>\n",
              "      <td>0</td>\n",
              "      <td>['rings']</td>\n",
              "      <td>renee zellweger stars as sonia , a young jewis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negR_902.txt</td>\n",
              "      <td>0</td>\n",
              "      <td>[\"there 're so many things to criticize about ...</td>\n",
              "      <td>there 're so many things to criticize about i ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negR_903.txt</td>\n",
              "      <td>0</td>\n",
              "      <td>[\"do n't let this movie fool you into believin...</td>\n",
              "      <td>do n't let this movie fool you into believing ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negR_904.txt</td>\n",
              "      <td>0</td>\n",
              "      <td>[\"is proof that hollywood does n't have a clue...</td>\n",
              "      <td>it 's a good thing most animated sci - fi movi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0292091c-68eb-4208-b3d1-c6dc6f3bc630')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0292091c-68eb-4208-b3d1-c6dc6f3bc630 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0292091c-68eb-4208-b3d1-c6dc6f3bc630');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-066c6add-2a76-4f39-9259-53ff00fb7a97\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-066c6add-2a76-4f39-9259-53ff00fb7a97')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-066c6add-2a76-4f39-9259-53ff00fb7a97 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 199,\n  \"fields\": [\n    {\n      \"column\": \"annotation_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 199,\n        \"samples\": [\n          \"negR_982.txt\",\n          \"negR_915.txt\",\n          \"posR_911.txt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"classification\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"evidences\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 198,\n        \"samples\": [\n          \"['but , there is almost no life to original script by michael laughlin and buck henry and this is \\\" t&c \\\\'s \\\" downfall']\",\n          \"['script keeps the show moving with some nice one -']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 199,\n        \"samples\": [\n          \"i remember really enjoying this movie when i saw it years ago . i guess my memory really sucks . there is very , very little that is funny in caddyshack . the laughs are few , and far between , and what there are really are n't that great . caddyshack , as the name implies , more or less centers on one young caddy working at an exclusive country club . michael o'keefe plays said caddy . why they cast this unknown , fairly untalented actor in the lead role is completely beyond me . the movie does n't seem to have a real plot , just a series of scenes that are little more than opportunities for the rest of the cast to mug at the camera . the only real story , if you can call it that , was a subplot involving the mentally disturbed greens keeper , bill murray , who is having his own private little war against a gopher who is ruining the course . most of the marginal laughs come from rodney dangerfield and ted knight mugging and overacting for the camera -- with painfully limited success . bill murray is slightly amusing in places , but fairly wasted . the biggest waste of all is chevy chase , who did n't even crack a smile on my face with his character 's lame zen - like approach to golfing . there are a few decent scenes involving the interaction between dangerfield and knight , but they are far too infrequent to carry the movie . i guess that 's what you get for basing a story around an unknown kid . i 'm not sure what the writers of this thing were thinking of , but i really think it was something far removed from comedy as they were putting pen to paper . nothing about this movie works . it would n't have taken a genius to figure out that this thing was n't going to fly . most of the scenes just could n't possibly be funny . it 's as if the writers where off in their own little brain damaged world . i 'm sure scenes involving chevy chase and his oneness with the golf ball were supposed to be funny . in reality , they were painfully embarrassing to watch . there is a scene at the club pool where all the caddies go wild for the \\\" hot babe \\\" of the movie walking by in her bikini . olive oil would have filled out this swimsuit better than this girl . everything about this movie was just completely implausible as far as the comedy was concerned . maybe if you were drunk out of you mind or high off some sort of illegal narcotic this thing might be funny . but for the rest of us , stay the hell away from caddyshack .\",\n          \"there 's only one presidential election every four years , but it seems like every few months we get another presidential conspiracy movie painted as _ the _ thriller of the year . in 1997 , we 've had absolute power , air force one , shadow conspiracy and murder at 1600 . this one is about as lame duck as old gerald ford , trying to bring us a complex plot of cover - up and intrigue but copping out over and over again with rehashes of action flick standbys . here 's what happens this time . it 's night at the white house . a secretary is having sex with some unidentified guy with a cute butt . the next day she 's dead and hotshot detective wesley snipes is called in . how do we know he 's a hotshot ? we 've seen the traditional action flick opener -- the clever hostage negotiation scene . it 's not so clever this time , consisting of snipes disarming a suicidal ex - government employee holding a gun to his head in the middle of the street . snipes is off to the white house , where he finds the secret service head ( the shiny bald head of daniel benzali ) wo n't cooperate with him at all . in fact , if not for the intervention of national security adviser alan alda , snipes would n't have been allowed in the white house at all . alda helps snipes out further , assigning a sexy secret service agent ( diane lane ) to act as his liaison . .. a very dangerous liaison . well , not really , i just wanted to say that . almost immediately , a suspect is found , an eccentric night janitor seen flirting with the deceased on one of the security videos . snipes does n't buy it , and launches into an independent investigation of his own , one that reveals planted evidence and romantic involvement by the president 's son . snipes ' partner , an always- wisecracking dennis miller , calls him up every once in awhile with more news and lane , who at first does n't believe snipes , eventually and predictably comes around , and risks her ass to break into social security storage and break out some classified information . for the first hour or so , murder at 1600 looks like it could be going somewhere interesting . sure , we have to sit through the lame opening sequence and plenty more lame scenes after that , but the whole murder in the white house thing makes for an interesting premise that is never quite delivered upon . snipes and lane do n't make for a bad action team , but with nothing to work with , they 're just cogs in the bad movie machine . dennis miller might as well not even be in the movie ; they waste his talents more in murder at 1600 than they did in bordello of blood , and that 's saying a lot . when you get to the last half - hour , the movie has descended metaphorically and literally into a wet sewer , busting out the old break - into - the - building underground climax . and when they finally reveal who killed the woman and why , you 'll wish you never sat through this movie at all . the \\\" 1600 \\\" in the movie 's title does n't represent an address , it represents the number of satisfied customers worldwide . serving the world for nearly 1/25th of a century !\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# convert the test dataset to a pandas dataframe\n",
        "test_df = pd.DataFrame(test_data)\n",
        "test_df.drop(columns=['docids','query', 'query_type'], inplace=True)\n",
        "test_df['evidences'] = test_df['evidences'].astype(str)\n",
        "\n",
        "test_rationales = test_df['evidences']\n",
        "test_reviews = [get_content(test_data, i) for i in range(test_size)]\n",
        "test_classes = torch.tensor([get_classes(test_data, i) for i in range(test_size)], dtype=torch.float)\n",
        "test_classes = torch.stack([test_classes]).squeeze(0) # convert the classes to binary tensor for two classes (pos & neg)\n",
        "\n",
        "print(\"Number of reviews in test data:\",len(test_reviews))\n",
        "print(\"Max seq length of reviews:\", np.max([len(review.split()) for review in test_reviews]))\n",
        "print(\"Size of training classes:\", train_classes.size())\n",
        "test_df.to_csv('./drive/MyDrive/NeuralNets/standardNeuralNets/test_data.csv', index=False)\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_WbCl45wz1E"
      },
      "source": [
        "Extract validation set from the val.jsonl file and create a dataframe for it similar to the training set and save it to a csv file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbHzxzSlwz1E"
      },
      "source": [
        "# Convert the reviews & rationales to their corresponding Glove embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from tqdm import tqdm\n",
        "\n",
        "def create_glove_dict(sequence, wv, set, embed_dim=50):\n",
        "    \"\"\"\n",
        "    Creates a dictionary mapping words in the vocabulary to their GloVe embeddings.\n",
        "    Words that don't exist are mapped to zero vectors.\n",
        "    \"\"\"\n",
        "    glove_dict = {}\n",
        "    empty_vec = np.zeros(embed_dim, dtype=np.float64)\n",
        "\n",
        "    for word in tqdm(sequence, desc=f\"Building {set} GloVe dictionary\"):\n",
        "        glove_dict[word] = wv[word] if word in wv else empty_vec\n",
        "\n",
        "    return glove_dict\n",
        "\n",
        "def get_w2GloVe(data, glove_dict, set, embed_dim=50, rationale=False):\n",
        "    \"\"\"\n",
        "    Retrieves the GloVe embeddings using the custom-built GloVe dictionary.\n",
        "    Args:\n",
        "        data: List of text reviews.\n",
        "        glove_dict (dict): custom-built GloVe dictionary.\n",
        "        embed_dim (int): Dimensions of GloVe embeddings.\n",
        "    Returns:\n",
        "        torch.Tensor: Padded tensor of GloVe embeddings to maintain uniform length.\n",
        "    \"\"\"\n",
        "    glove_reviews = []\n",
        "\n",
        "    if rationale:\n",
        "        for review in tqdm(data, desc=f\"Retrieving {set} GloVe Word Embeddings\"):\n",
        "            tokens = \",\".join(review)\n",
        "            words = tokens.split()\n",
        "            embeddings = [glove_dict.get(word, np.zeros(embed_dim)) for word in words]\n",
        "            glove_reviews.append(torch.tensor(embeddings, dtype=torch.float))\n",
        "    else:\n",
        "        for review in tqdm(data, desc=f\"Retrieving {set} GloVe Word Embeddings\"):\n",
        "            words = review.split()\n",
        "            embeddings = [glove_dict.get(word, np.zeros(embed_dim)) for word in words]\n",
        "            glove_reviews.append(torch.tensor(embeddings, dtype=torch.float))\n",
        "\n",
        "    return pad_sequence(glove_reviews, batch_first=True)"
      ],
      "metadata": {
        "id": "0ri5kC6oQJag"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHdxXI-3cSIM"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "print(f\"----------------------------------------------------------------------------------------\\nProcessing Reviews\\n----------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "# Extract vocabulary(distinct words) from training, validation, and test data\n",
        "train_vocab = set(word for review in train_df['content'] for word in review.split())\n",
        "val_vocab = set(word for review in val_df['content'] for word in review.split())\n",
        "test_vocab = set(word for review in test_df['content'] for word in review.split())\n",
        "\n",
        "# Build the GloVe dictionary for the reviews\n",
        "glove_dict = create_glove_dict(train_vocab, wv, \"training\")\n",
        "glove_dict.update(create_glove_dict(val_vocab, wv, \"validation\"))\n",
        "glove_dict.update(create_glove_dict(test_vocab, wv, \"test\"))\n",
        "\n",
        "# Convert reviews to glove embeddings\n",
        "train_review_gloves = get_w2GloVe(train_df['content'], glove_dict, \"training\")\n",
        "val_review_gloves = get_w2GloVe(val_df['content'], glove_dict, \"validation\")\n",
        "test_review_gloves = get_w2GloVe(test_df['content'], glove_dict, \"test\")\n",
        "\n",
        "print(f\"\\n----------------------------------------------------------------------------------------\\nProcessing Rationales\\n----------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "#Extract vocabulary(distinct words) from training, validation, and test data for the rationales\n",
        "train_rationale_vocab = set(word for rationale in train_rationales for word in rationale.split())\n",
        "val_rationale_vocab = set(word for rationale in val_rationales for word in rationale.split())\n",
        "test_rationale_vocab = set(word for rationale in test_rationales for word in rationale.split())\n",
        "\n",
        "# Build the GloVe dictionary for the rationales\n",
        "dict_rat = create_glove_dict(train_rationale_vocab, wv, \"training\")\n",
        "dict_rat.update(create_glove_dict(val_rationale_vocab, wv, \"validation\"))\n",
        "dict_rat.update(create_glove_dict(test_rationale_vocab, wv, \"test\"))\n",
        "\n",
        "# Convert rationales to glove embeddings\n",
        "train_rationale_gloves = get_w2GloVe(train_rationales, glove_dict, \"training\", rationale=True)\n",
        "val_rationale_gloves = get_w2GloVe(val_rationales, glove_dict, \"validation\", rationale=True)\n",
        "test_rationale_gloves = get_w2GloVe(test_rationales, glove_dict, \"test\", rationale=True)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsVWqfEmcSIM"
      },
      "source": [
        "Save the GloVe embeddings to local files for faster Access."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Pm21m4EZwz1F",
        "outputId": "514d3a0f-b2d3-4275-b024-1ade403b66ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nwith open(\"./drive/MyDrive/NeuralNets/standardNeuralNets/train_reviews.pkl\", \"wb\") as f:\\n    pickle.dump(train_review_gloves, f)\\n\\nwith open(\"./drive/MyDrive/NeuralNets/standardNeuralNets/val_reviews.pkl\", \"wb\") as f:\\n    pickle.dump(val_review_gloves, f)\\n\\nwith open(\"./drive/MyDrive/NeuralNets/standardNeuralNets/test_reviews.pkl\", \"wb\") as f:\\n    pickle.dump(test_review_gloves, f)\\n\\nwith open(\"./drive/MyDrive/NeuralNets/standardNeuralNets/train_rationales.pkl\", \"wb\") as f:\\n    pickle.dump(train_rationale_gloves, f)\\n\\nwith open(\"./drive/MyDrive/NeuralNets/standardNeuralNets/val_rationales.pkl\", \"wb\") as f:\\n    pickle.dump(val_rationale_gloves, f)\\n\\nwith open(\"./drive/MyDrive/NeuralNets/standardNeuralNets/test_rationales.pkl\", \"wb\") as f:\\n    pickle.dump(test_rationale_gloves, f)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "from torch import Tensor\n",
        "from typing import Dict, List, Optional, Tuple, Union\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from tqdm import tqdm\n",
        "\"\"\"\n",
        "with open(\"./drive/MyDrive/NeuralNets/standardNeuralNets/train_reviews.pkl\", \"wb\") as f:\n",
        "    pickle.dump(train_review_gloves, f)\n",
        "\n",
        "with open(\"./drive/MyDrive/NeuralNets/standardNeuralNets/val_reviews.pkl\", \"wb\") as f:\n",
        "    pickle.dump(val_review_gloves, f)\n",
        "\n",
        "with open(\"./drive/MyDrive/NeuralNets/standardNeuralNets/test_reviews.pkl\", \"wb\") as f:\n",
        "    pickle.dump(test_review_gloves, f)\n",
        "\n",
        "with open(\"./drive/MyDrive/NeuralNets/standardNeuralNets/train_rationales.pkl\", \"wb\") as f:\n",
        "    pickle.dump(train_rationale_gloves, f)\n",
        "\n",
        "with open(\"./drive/MyDrive/NeuralNets/standardNeuralNets/val_rationales.pkl\", \"wb\") as f:\n",
        "    pickle.dump(val_rationale_gloves, f)\n",
        "\n",
        "with open(\"./drive/MyDrive/NeuralNets/standardNeuralNets/test_rationales.pkl\", \"wb\") as f:\n",
        "    pickle.dump(test_rationale_gloves, f)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TBPAqY3cSIN"
      },
      "source": [
        "# Extract the GloVe embeddings created above and a create a copy before batching them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "WgQLyJDGcSIN"
      },
      "outputs": [],
      "source": [
        "with open(\"./drive/MyDrive/NeuralNets/standardNeuralNets/train_reviews.pkl\", \"rb\") as f:\n",
        "    train_in = pickle.load(f)\n",
        "\n",
        "with open(\"./drive/MyDrive/NeuralNets/standardNeuralNets/train_rationales.pkl\", \"rb\") as f:\n",
        "    train_ev = pickle.load(f)\n",
        "\n",
        "with open(\"./drive/MyDrive/NeuralNets/standardNeuralNets/val_reviews.pkl\", \"rb\") as f:\n",
        "    val_in = pickle.load(f)\n",
        "\n",
        "with open(\"./drive/MyDrive/NeuralNets/standardNeuralNets/val_rationales.pkl\", \"rb\") as f:\n",
        "    val_ev = pickle.load(f)\n",
        "\n",
        "with open(\"./drive/MyDrive/NeuralNets/standardNeuralNets/test_reviews.pkl\", \"rb\") as f:\n",
        "    test_in = pickle.load(f)\n",
        "\n",
        "with open(\"./drive/MyDrive/NeuralNets/standardNeuralNets/test_rationales.pkl\", \"rb\") as f:\n",
        "    test_ev = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_token = train_reviews[506].split()\n",
        "print(review_token[3])\n",
        "word = train_in[506][3]\n",
        "print(train_in[506][3])\n",
        "vec = wv['extraordinarily']\n",
        "print(vec)\n",
        "assert (word == vec).all()"
      ],
      "metadata": {
        "id": "3o811smq4VLk",
        "outputId": "53f3f97f-be0b-423a-ab57-5db2b1566dea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraordinarily\n",
            "tensor([ 0.5632, -0.3914, -0.5143, -0.5885,  0.3773, -0.2105,  0.6533,  0.3574,\n",
            "         0.1148,  0.8625, -0.5586, -0.0243,  0.4358,  0.5623, -0.1002, -0.1830,\n",
            "         0.6990,  0.3179,  0.4530, -0.2554, -0.6209,  0.0255, -0.0934, -0.2264,\n",
            "         0.6017, -0.6755, -0.4472,  0.7017,  0.6341,  0.9313,  1.7065, -0.4970,\n",
            "         1.1293, -0.6887,  0.3636,  0.3428, -0.2177,  1.3491, -0.8561, -0.7610,\n",
            "        -0.8314,  0.1092,  0.1539,  0.5528,  0.2584, -0.5015, -0.2010,  0.3027,\n",
            "         0.1052,  1.2230])\n",
            "[ 0.56323  -0.39137  -0.51434  -0.58849   0.37726  -0.21051   0.65334\n",
            "  0.35739   0.1148    0.86252  -0.55858  -0.02432   0.43576   0.56232\n",
            " -0.10024  -0.18301   0.69904   0.31791   0.45302  -0.25536  -0.62086\n",
            "  0.025509 -0.093439 -0.22638   0.60171  -0.67547  -0.44724   0.7017\n",
            "  0.6341    0.93127   1.7065   -0.49698   1.1293   -0.68874   0.36359\n",
            "  0.3428   -0.21766   1.3491   -0.8561   -0.76098  -0.83144   0.10922\n",
            "  0.15385   0.55284   0.25841  -0.50152  -0.20098   0.30271   0.10516\n",
            "  1.223   ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSzDGF43ytnN"
      },
      "source": [
        "Convert the training, validation, and test data(GloVe representations) including the rationales to batches using DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "wsgVwakDytnO"
      },
      "outputs": [],
      "source": [
        "train_inputs = TensorDataset(train_in, train_ev, train_classes)\n",
        "val_inputs = TensorDataset(val_in, val_ev, val_classes)\n",
        "test_inputs = TensorDataset(test_in, test_ev, test_classes)\n",
        "\n",
        "train_loader = DataLoader(train_inputs, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_inputs, batch_size=25, shuffle=False)\n",
        "test_loader = DataLoader(test_inputs, batch_size=25, shuffle=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFqiLpR3Byqh",
        "outputId": "20a5c5ba-a03f-4c9a-975f-5364f36a2545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 2809, 50])\n",
            "torch.Size([32, 300, 50])\n",
            "torch.Size([32])\n",
            "torch.Size([25, 1880, 50])\n",
            "torch.Size([25, 162, 50])\n",
            "torch.Size([25])\n",
            "torch.Size([25, 2122, 50])\n",
            "torch.Size([25, 208, 50])\n",
            "torch.Size([25])\n"
          ]
        }
      ],
      "source": [
        "train_inp, train_evi, train_classg = next(iter(train_loader))\n",
        "print(train_inp.size())\n",
        "print(train_evi.size())\n",
        "print(train_classg.size())\n",
        "\n",
        "val_inp, val_evi, val_classg = next(iter(val_loader))\n",
        "print(val_inp.size())\n",
        "print(val_evi.size())\n",
        "print(val_classg.size())\n",
        "\n",
        "test_inp, test_evi, test_classg = next(iter(test_loader))\n",
        "print(test_inp.size())\n",
        "print(test_evi.size())\n",
        "print(test_classg.size())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPQy0BjBytnO"
      },
      "source": [
        "# Convolutional Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "smXuMplUytnO"
      },
      "outputs": [],
      "source": [
        "from typing import List, Optional, Tuple, Union\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import lime\n",
        "from lime.lime_text import LimeTextExplainer # type: ignore\n",
        "\n",
        "class LimeCNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 embed_size: int,\n",
        "                 cnn_config: list,\n",
        "                 pool_size: int,\n",
        "                 max_seq_len: int,\n",
        "                 num_classes: int) -> None:\n",
        "        super(LimeCNN, self).__init__()\n",
        "\n",
        "        # Create convolution layers dynamically from cnn_config\n",
        "\n",
        "        self.convLayer = nn.ModuleList(\n",
        "          [\n",
        "            nn.Conv1d(config['in_channels'], config['out_channels'], kernel_size=config['kernel_size'], padding=config['padding'], bias = config['bias'])\n",
        "            for config in cnn_config\n",
        "          ]\n",
        "        )\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pooling = nn.MaxPool1d(pool_size)\n",
        "        self.droput = nn.Dropout(0.5)\n",
        "\n",
        "        fc_in_sizes = []\n",
        "        for config in cnn_config:\n",
        "          out_size = max_seq_len + 2 * config['padding'] - config['kernel_size'] + 1  # Output size after convolution\n",
        "          out_size = (out_size - pool_size) // pool_size + 1  # Output size after pooling\n",
        "          fc_in_sizes.append(config['out_channels'] * out_size)\n",
        "\n",
        "        # Sum the output sizes of all convolutional layers to get the total input size for the fully connected layer\n",
        "        fc_in = sum(fc_in_sizes)\n",
        "\n",
        "        self.fc = nn.Linear(fc_in, num_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = x.permute(0, 2, 1)  # (batch, embed_size, sequence_length)\n",
        "        if x.shape[2] != 2809:\n",
        "          x = nn.Linear(x.shape[2], 2809)(x)\n",
        "        conv_out = [self.relu(conv_layer(x)) for conv_layer in self.convLayer]\n",
        "        #print(f\"Shape after convolution: {conv_out[0].size()}\")\n",
        "        pooled_out = [self.pooling(out) for out in conv_out]\n",
        "        #print(f\"Shape after pooling: {pooled_out[0].size()}\")\n",
        "        flat_out = torch.cat([pooled.squeeze(dim=2) for pooled in pooled_out], dim=-1)\n",
        "        #print(f\"Shape after concatenation: {flat_out.size()}\")\n",
        "        fc_in = self.droput(flat_out)\n",
        "        fc_in = fc_in.view(fc_in.size(0), -1)\n",
        "        #print(\"shape before going to fc:\", fc_in.size())\n",
        "        y = self.fc(fc_in).squeeze(1)\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def set_random_seed(seed):\n",
        "  torch.manual_seed(seed)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)"
      ],
      "metadata": {
        "id": "C9Q0TpiGScfH"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy(predictions, true_labels):\n",
        "  num_labels = true_labels.size(0)\n",
        "  #print(predictions.size(), true_labels.size())\n",
        "  predicted_labels = (predictions >= 0.5).int()\n",
        "  num_correct = torch.sum(predicted_labels == true_labels).item()\n",
        "  accuracy = num_correct / num_labels\n",
        "  return accuracy\n"
      ],
      "metadata": {
        "id": "RxH1OT_7lxWJ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_model(model, val_set, criterion):\n",
        "  model.eval()\n",
        "  total_val_loss = []\n",
        "  val_preds = []\n",
        "  best_val_loss = float('inf')\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "      inputs, rationales, labels = batch\n",
        "      pred = model(inputs)\n",
        "      val_preds.append(pred)\n",
        "      loss = criterion(pred, labels)\n",
        "      total_val_loss.append(loss.item())\n",
        "\n",
        "  avg_val_loss = np.mean(total_val_loss)\n",
        "  val_preds = torch.cat(val_preds, dim=0)\n",
        "  val_preds = (val_preds >= 0.5).int()\n",
        "  val_acc = calc_accuracy(val_preds, val_classes.int())\n",
        "\n",
        "  if avg_val_loss < best_val_loss:\n",
        "    best_val_loss = avg_val_loss\n",
        "    torch.save(model.state_dict(), \"best_model_state.pt\")\n",
        "\n",
        "  return avg_val_loss, val_acc"
      ],
      "metadata": {
        "id": "ah5wQMs6krhD"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ERAlignment_score(idx, explanations, test=False, tain=False):\n",
        "  if test:\n",
        "    rationales = test_rationales[idx]\n",
        "  elif tain:\n",
        "    rationales = train_rationales[idx]\n",
        "  else:\n",
        "    rationales = val_rationales[idx]\n",
        "\n",
        "print(test_rationales[0])"
      ],
      "metadata": {
        "id": "huXWCo_4jcYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_set, val_set, optimizer, lr_scheduler, criterion, n_epochs, lr):\n",
        "  train_losses = []\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    total_loss = []\n",
        "    preds_list = []\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs}\"):\n",
        "      inputs, rationales, labels = batch\n",
        "\n",
        "      pred = model(inputs)\n",
        "      preds_list.append(pred)\n",
        "\n",
        "      loss = criterion(pred, labels)\n",
        "      total_loss.append(loss.item())\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    avg_train_loss = np.mean(total_loss)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    y_hats = torch.cat(preds_list, dim=0)\n",
        "    y_hats = (y_hats >= 0.5).int()\n",
        "    train_acc = calc_accuracy(y_hats, train_classes.int())\n",
        "\n",
        "    avg_val_loss, val_acc = validate_model(model, val_set, criterion)\n",
        "\n",
        "    print(f\"Train Loss: {avg_train_loss:.4f} | Train acc: {train_acc:.4f} | Val Loss: {avg_val_loss:.4f} | val acc: {val_acc}\")\n",
        "    print(\"------------------------------------------------------------------------------\")\n",
        "\n",
        "    lr_scheduler.step(avg_val_loss)\n",
        "    print(\"current learning rate:\", lr_scheduler.get_last_lr(),\"\\n\")\n",
        "\n",
        "  return y_hats, train_losses\n"
      ],
      "metadata": {
        "id": "kC8N1heiESfx"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
        "\n",
        "# Load the model configuration from a JSON file\n",
        "with open(\"./drive/MyDrive/NeuralNets/standardNeuralNets/model_config.json\", \"r\") as f:\n",
        "    model_config = json.load(f)\n"
      ],
      "metadata": {
        "id": "XhcT7m2zU3_6"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_random_seed(14)\n",
        "\n",
        "model = LimeCNN(embed_size=50, cnn_config=model_config, pool_size=3, max_seq_len=2809, num_classes=1)\n",
        "\n",
        "lr, n_epochs = 1e-4, 50\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "\n",
        "lr_sched = ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=5)\n",
        "\n",
        "Y_HAT, LOSSES = train_model(model=model,\n",
        "                            train_set=train_loader,\n",
        "                            val_set=val_loader,\n",
        "                            optimizer=optimizer,\n",
        "                            lr_scheduler=lr_sched,\n",
        "                            criterion=loss_func,\n",
        "                            n_epochs=n_epochs,\n",
        "                            lr=lr)"
      ],
      "metadata": {
        "id": "7OFXoVgfSsNU",
        "outputId": "84d483cd-4836-4c1d-cfeb-7d1e5efefa95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/50: 100%|| 50/50 [00:03<00:00, 12.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6952 | Train acc: 0.4988 | Val Loss: 0.6947 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [0.0001] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/50: 100%|| 50/50 [00:03<00:00, 14.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6883 | Train acc: 0.4969 | Val Loss: 0.6957 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [0.0001] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/50: 100%|| 50/50 [00:03<00:00, 13.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6880 | Train acc: 0.4894 | Val Loss: 0.6879 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [0.0001] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/50: 100%|| 50/50 [00:03<00:00, 13.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6878 | Train acc: 0.4963 | Val Loss: 0.6997 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [0.0001] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/50: 100%|| 50/50 [00:03<00:00, 14.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6875 | Train acc: 0.4925 | Val Loss: 0.6828 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [0.0001] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/50: 100%|| 50/50 [00:03<00:00, 14.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6823 | Train acc: 0.4881 | Val Loss: 0.7046 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [0.0001] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/50: 100%|| 50/50 [00:04<00:00, 12.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6829 | Train acc: 0.5150 | Val Loss: 0.6860 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [0.0001] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/50: 100%|| 50/50 [00:03<00:00, 14.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6806 | Train acc: 0.5006 | Val Loss: 0.6922 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [0.0001] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/50: 100%|| 50/50 [00:03<00:00, 12.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6798 | Train acc: 0.4844 | Val Loss: 0.6891 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [0.0001] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/50: 100%|| 50/50 [00:03<00:00, 13.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6800 | Train acc: 0.5069 | Val Loss: 0.6906 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [0.0001] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/50: 100%|| 50/50 [00:03<00:00, 14.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6794 | Train acc: 0.5075 | Val Loss: 0.6909 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [8e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/50: 100%|| 50/50 [00:03<00:00, 13.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6758 | Train acc: 0.5088 | Val Loss: 0.6955 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [8e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/50: 100%|| 50/50 [00:03<00:00, 13.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6755 | Train acc: 0.4900 | Val Loss: 0.7033 | val acc: 0.495\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [8e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/50: 100%|| 50/50 [00:03<00:00, 14.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6757 | Train acc: 0.5188 | Val Loss: 0.6946 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [8e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/50: 100%|| 50/50 [00:03<00:00, 14.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6752 | Train acc: 0.4906 | Val Loss: 0.7073 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [8e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/50: 100%|| 50/50 [00:03<00:00, 12.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6721 | Train acc: 0.5081 | Val Loss: 0.6978 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [8e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/50: 100%|| 50/50 [00:03<00:00, 14.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6722 | Train acc: 0.5019 | Val Loss: 0.6979 | val acc: 0.49\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [6.400000000000001e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/50: 100%|| 50/50 [00:03<00:00, 12.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6734 | Train acc: 0.4919 | Val Loss: 0.6965 | val acc: 0.495\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [6.400000000000001e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/50: 100%|| 50/50 [00:03<00:00, 13.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6717 | Train acc: 0.4994 | Val Loss: 0.6974 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [6.400000000000001e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/50: 100%|| 50/50 [00:03<00:00, 14.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6721 | Train acc: 0.4975 | Val Loss: 0.6907 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [6.400000000000001e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/50: 100%|| 50/50 [00:03<00:00, 12.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6683 | Train acc: 0.4988 | Val Loss: 0.6840 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [6.400000000000001e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/50: 100%|| 50/50 [00:03<00:00, 13.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6675 | Train acc: 0.5006 | Val Loss: 0.7052 | val acc: 0.49\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [6.400000000000001e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/50: 100%|| 50/50 [00:03<00:00, 14.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6687 | Train acc: 0.5006 | Val Loss: 0.7084 | val acc: 0.495\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [5.120000000000001e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/50: 100%|| 50/50 [00:03<00:00, 13.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6679 | Train acc: 0.5006 | Val Loss: 0.6966 | val acc: 0.505\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [5.120000000000001e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/50: 100%|| 50/50 [00:03<00:00, 13.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6678 | Train acc: 0.4800 | Val Loss: 0.6972 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [5.120000000000001e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/50: 100%|| 50/50 [00:03<00:00, 14.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6675 | Train acc: 0.5094 | Val Loss: 0.7014 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [5.120000000000001e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/50: 100%|| 50/50 [00:03<00:00, 13.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6685 | Train acc: 0.5044 | Val Loss: 0.6927 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [5.120000000000001e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/50: 100%|| 50/50 [00:03<00:00, 13.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6644 | Train acc: 0.4944 | Val Loss: 0.7045 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [5.120000000000001e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/50: 100%|| 50/50 [00:03<00:00, 14.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6654 | Train acc: 0.4963 | Val Loss: 0.6997 | val acc: 0.52\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [4.0960000000000014e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/50: 100%|| 50/50 [00:03<00:00, 13.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6654 | Train acc: 0.5106 | Val Loss: 0.7034 | val acc: 0.485\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [4.0960000000000014e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/50: 100%|| 50/50 [00:03<00:00, 13.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6662 | Train acc: 0.4938 | Val Loss: 0.7013 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [4.0960000000000014e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/50: 100%|| 50/50 [00:03<00:00, 14.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6674 | Train acc: 0.4913 | Val Loss: 0.6985 | val acc: 0.485\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [4.0960000000000014e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/50: 100%|| 50/50 [00:03<00:00, 13.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6635 | Train acc: 0.4944 | Val Loss: 0.6939 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [4.0960000000000014e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/50: 100%|| 50/50 [00:03<00:00, 13.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6651 | Train acc: 0.5131 | Val Loss: 0.7071 | val acc: 0.49\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [4.0960000000000014e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/50: 100%|| 50/50 [00:03<00:00, 14.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6663 | Train acc: 0.4938 | Val Loss: 0.6951 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [3.2768000000000016e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/50: 100%|| 50/50 [00:03<00:00, 13.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6619 | Train acc: 0.5038 | Val Loss: 0.7053 | val acc: 0.495\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [3.2768000000000016e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/50: 100%|| 50/50 [00:03<00:00, 13.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6591 | Train acc: 0.5044 | Val Loss: 0.7066 | val acc: 0.49\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [3.2768000000000016e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/50: 100%|| 50/50 [00:03<00:00, 14.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6628 | Train acc: 0.5056 | Val Loss: 0.7057 | val acc: 0.495\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [3.2768000000000016e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/50: 100%|| 50/50 [00:03<00:00, 13.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6627 | Train acc: 0.4956 | Val Loss: 0.7163 | val acc: 0.48\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [3.2768000000000016e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/50: 100%|| 50/50 [00:03<00:00, 13.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6604 | Train acc: 0.4919 | Val Loss: 0.6991 | val acc: 0.505\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [3.2768000000000016e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/50: 100%|| 50/50 [00:03<00:00, 14.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6631 | Train acc: 0.4900 | Val Loss: 0.7018 | val acc: 0.495\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [2.6214400000000015e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/50: 100%|| 50/50 [00:03<00:00, 13.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6621 | Train acc: 0.4913 | Val Loss: 0.7035 | val acc: 0.49\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [2.6214400000000015e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/50: 100%|| 50/50 [00:03<00:00, 13.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6630 | Train acc: 0.5025 | Val Loss: 0.7022 | val acc: 0.495\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [2.6214400000000015e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/50: 100%|| 50/50 [00:03<00:00, 14.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6640 | Train acc: 0.5088 | Val Loss: 0.7057 | val acc: 0.49\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [2.6214400000000015e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/50: 100%|| 50/50 [00:03<00:00, 13.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6601 | Train acc: 0.5031 | Val Loss: 0.7026 | val acc: 0.5\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [2.6214400000000015e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/50: 100%|| 50/50 [00:03<00:00, 12.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6609 | Train acc: 0.4906 | Val Loss: 0.7048 | val acc: 0.515\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [2.6214400000000015e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/50: 100%|| 50/50 [00:03<00:00, 14.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6617 | Train acc: 0.4875 | Val Loss: 0.6966 | val acc: 0.505\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [2.0971520000000012e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/50: 100%|| 50/50 [00:03<00:00, 13.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6577 | Train acc: 0.4869 | Val Loss: 0.7036 | val acc: 0.505\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [2.0971520000000012e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/50: 100%|| 50/50 [00:03<00:00, 13.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6600 | Train acc: 0.4919 | Val Loss: 0.7031 | val acc: 0.49\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [2.0971520000000012e-05] \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/50: 100%|| 50/50 [00:03<00:00, 14.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.6579 | Train acc: 0.5006 | Val Loss: 0.6991 | val acc: 0.495\n",
            "------------------------------------------------------------------------------\n",
            "current learning rate: [2.0971520000000012e-05] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "nL7dPN8rmMzL",
        "outputId": "90a8582c-a924-48b0-eeee-58cefb6e0a1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1600])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "preds = Y_HAT\n",
        "print(preds.size())\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(train_classes.detach().numpy(), preds.detach().numpy())\n",
        "\n",
        "# Plot using seaborn\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Positive\", \"Negative\"], yticklabels=[\"Positive\", \"Negative\"])\n",
        "\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "preds_list = []\n",
        "with torch.no_grad():\n",
        "  for batch in test_loader:\n",
        "    inputs, rationales, labels = batch\n",
        "    pred = model(inputs)\n",
        "    preds_list.append(pred)\n",
        "\n",
        "y_hat = torch.cat(preds_list, dim=0)\n",
        "y_hat = (y_hat >= 0.5).int()\n",
        "test_acc = calc_accuracy(y_hat, test_classes)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "preds = y_hat\n",
        "print(preds.size())\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(test_classes.numpy(), preds.detach().numpy())\n",
        "\n",
        "# Plot using seaborn\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Positive\", \"Negative\"], yticklabels=[\"Positive\", \"Negative\"])\n",
        "\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZI2owJu0Xe46",
        "outputId": "6c86c649-f0e0-420c-e484-6c25bcc7d0d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.4975\n",
            "torch.Size([199])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}